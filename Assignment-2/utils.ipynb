{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gensim\n",
    "import numpy as np\n",
    "import transformers\n",
    "from typing import Callable\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Embeddings/GoogleNews-vectors-negative300.bin.gz\"     # Word2Vec\n",
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divyajeet Singh\\AppData\\Local\\Temp\\ipykernel_4932\\4275181089.py:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(\"Embeddings/glove.42B.300d/glove.42B.300d.txt\", target)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "target = get_tmpfile(\"temp.txt\")\n",
    "glove2word2vec(\"Embeddings/glove.42B.300d/glove.42B.300d.txt\", target)\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(target)\n",
    "\n",
    "model.save_word2vec_format(\"Embeddings/glove.42B.300d.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Embeddings/glove.42B.300d.bin.gz\"                       # GloVe\n",
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Embeddings/cc.en.300.bin.gz\"                          # FastText\n",
    "embedding = gensim.models.fasttext.load_facebook_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset: int, embeddings: str):\n",
    "    \"\"\"\n",
    "    Loads the given dataset and returns the train, test, and validation\n",
    "    sets with the corresponding labels.\n",
    "    :params:\n",
    "        - dataset: The dataset to load. Must be 1 or 2.\n",
    "        - embeddings: The word-embeddings to use. Must be \"Word2Vec\", \"GloVe\", or \"FastText\" (case-insensitive).\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_err = \"Invalid embeddings. Must be 'Word2Vec', 'GloVe', or 'FastText'.\"\n",
    "    dataset_err = \"Invalid dataset number. Must be 1 or 2.\"\n",
    "    embeddings = embeddings.casefold()\n",
    "\n",
    "    path = r\"Assignment-2/Datasets/preprocessed/\"\n",
    "    train_path, test_path, val_path = [\n",
    "        os.path.join(path, dataset, f\"{dataset}_{x}.json\") for x in [\"train\", \"test\", \"val\"]\n",
    "    ]\n",
    "\n",
    "    assert embeddings in [\"word2vec\", \"glove\", \"fasttext\"], embeddings_err\n",
    "\n",
    "    # path = rf\"Assignment-2/Datasets/preprocessed/dataset_{dataset}\"\n",
    "    # train_path, test_path, val_path = [os.path.join(path, f\"{x}.json\") for x in [\"train\", \"test\", \"val\"]]\n",
    "\n",
    "    with open(train_path) as train, open(test_path) as test, open(val_path) as val:\n",
    "        train_data = json.load(train)\n",
    "        test_data = json.load(test)\n",
    "        val_data = json.load(val)\n",
    "\n",
    "    print(\"Loading Embeddings...\")\n",
    "    if embeddings == \"word2vec\":\n",
    "        model = \"Assignment-2/Embeddings/GoogleNews-vectors-negative300.bin.gz\"\n",
    "        embedding = gensim.models.KeyedVectors.load_word2vec_format(model, binary=True)\n",
    "    elif embeddings == \"glove\":\n",
    "        model = \"Assignment-2/Embeddings/glove.42B.300d.bin.gz\"\n",
    "        embedding = gensim.models.KeyedVectors.load_word2vec_format(model, binary=True)\n",
    "    else:\n",
    "        model = \"Assignment-2/Embeddings/cc.en.300.bin.gz\"\n",
    "        embedding = gensim.models.fasttext.load_facebook_model(model).wv\n",
    "\n",
    "    LABELS = set()\n",
    "    for data in train_data.values():\n",
    "        LABELS.update(data[\"labels\"])\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(sorted(LABELS))\n",
    "\n",
    "    print(\"Preprocessing Data...\")\n",
    "    DATA = [[], []], [[], []], [[], []]\n",
    "    for i, dataset in enumerate([train_data, test_data, val_data]):\n",
    "        for data in dataset.values():\n",
    "            DATA[i][0].append(data[\"text\"].split())\n",
    "            DATA[i][1].append(data[\"labels\"])\n",
    "    (TRAIN_DATA, TRAIN_LABELS), (TEST_DATA, TEST_LABELS), (VAL_DATA, VAL_LABELS) = DATA\n",
    "\n",
    "    train_set = CustomDataset(TRAIN_DATA, TRAIN_LABELS, encoder, embedding)\n",
    "    test_set = CustomDataset(TEST_DATA, TEST_LABELS, encoder, embedding)\n",
    "    val_set = CustomDataset(VAL_DATA, VAL_LABELS, encoder, embedding)\n",
    "\n",
    "    return train_set, test_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for dataset_1 and dataset_2.\n",
    "    :attrs:\n",
    "        - data: The data of the dataset. Each element is a list of words.\n",
    "        - labels: The labels of the dataset. Each element is a list of labels\n",
    "            for each word of the sentence.\n",
    "        - encoder: The (already fitted) label-encoder for the labels.\n",
    "        - embedding: The word-embedding to use for the dataset. It must have\n",
    "            a key_to_index attribute attribute (to convert words to indices).\n",
    "\n",
    "    The dataset preprocesses the input data and labels. 'data' is stored as\n",
    "    a Tensor of word-indices, and 'labels' is stored as a Tensor of label-indices.\n",
    "    \"\"\"\n",
    "\n",
    "    data: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    encoder: LabelEncoder\n",
    "    embeddings: gensim.models.keyedvectors.KeyedVectors | gensim.models.fasttext.FastTextKeyedVectors\n",
    "\n",
    "    def __init__(self, data: list[list[str]], labels: list[list[str]], encoder, embeddings):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.encoder = encoder\n",
    "        self.embeddings = embeddings\n",
    "        self._encode()\n",
    "        self._pad()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns the data and target at the given index. Converts each\n",
    "        sentence into a tensor of word indices using the chosen word-embeddings.\n",
    "        \"\"\"\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def _encode(self) -> None:\n",
    "        \"\"\"\n",
    "        Converts all sentences to their corresponding word-indices and\n",
    "        encodes the labels using the label-encoder.\n",
    "        \"\"\"\n",
    "        unk = len(self.embeddings.key_to_index) - 1\n",
    "        self.data = [\n",
    "            torch.tensor([self.embeddings.key_to_index.get(word, unk) for word in sentence])\n",
    "            for sentence in self.data\n",
    "        ]\n",
    "        self.labels = [torch.LongTensor(self.encoder.transform(label)) for label in self.labels]\n",
    "\n",
    "    def _pad(self) -> None:\n",
    "        \"\"\"\n",
    "        Pads all sentences to the maximum length. Currently, the padding\n",
    "        value for the labels is set to \"O\", which may not be ideal.\n",
    "        \"\"\"\n",
    "        padding_value = self.encoder.transform([\"O\"])[0]\n",
    "        self.data = torch.nn.utils.rnn.pad_sequence(self.data, batch_first=True)\n",
    "        self.labels = torch.nn.utils.rnn.pad_sequence(self.labels, batch_first=True, padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Preprocessing Data...\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, val_set = load_dataset(\"NER\", \"Word2Vec\")\n",
    "\n",
    "encoder = train_set.encoder\n",
    "embeddings = train_set.embeddings\n",
    "# # This part handles the <UNK> token, i.e. OOV words. Currently, OOV words are directly set to 0s, which is not ideal.\n",
    "embedding_matrix = torch.FloatTensor(embeddings.vectors)\n",
    "embedding_matrix = torch.cat([embedding_matrix, torch.zeros(1, embedding_matrix.shape[1])])\n",
    "embedding.key_to_index[\"<UNK>\"] = len(embedding.key_to_index)\n",
    "embedding.index_to_key.append(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_MODEL = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.fasttext.FastTextKeyedVectors"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(FASTTEXT_MODEL.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDING_LAYER = torch.nn.Embedding.from_pretrained(embedding_matrix)\n",
    "word_embedding = EMBEDING_LAYER(torch.tensor([embedding.key_to_index.get(word) for word in \"the quick brown fox\".split()]))\n",
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'was', 'also', 'asked', 'whether', 'Agya', '<span', 'class=\"hidden_text\"', 'id=\"span_5\">', 'CRA', 'No.326-DB', 'of', '1998', '6</span>', 'Kaur,', 'mother-in-law', 'of', 'the', 'deceased', 'lived', 'separately', 'from', 'Tarlochan', 'Singh.']\n",
      "['5.2', 'CW3', 'Mr', 'Vijay', 'Mishra', ',', 'Deputy', 'Manager,', 'HDFC', 'Bank,', 'Noida,', 'UP', 'has', 'deposed', 'that', 'complainant', 'had', 'a', 'current', 'account', 'with', 'HDFC', 'Bank', 'in', 'the', 'year', '2004\\xad2005.']\n",
      "['You', 'are', 'hereby', 'asked', 'not', 'to', 'carry', 'out', 'any', 'construction', 'work', 'of', 'the', 'said', 'building', 'hereafter', 'since', 'the', 'agreement', 'has', 'been', 'terminated\".']\n",
      "['After', 'all', 'the', 'steps', 'at', 'the', 'stage', 'of', 'investigation', 'has', 'to', 'be', 'reported', 'before', 'the', 'Court', 'and', 'the', 'order', 'passed', 'thereon', 'is', 'obviously', 'judicial', 'order', 'and', 'this', 'takes', 'clear', 'note', 'of', 'the', 'agony', 'of', 'the', 'learned', 'Counsels.']\n",
      "['PW--2', 'Chandregowda', 'is', 'the', 'younger', 'brother', 'of', 'bi-hglllltleceased.']\n"
     ]
    }
   ],
   "source": [
    "subset = train_data[:5]\n",
    "for sentence in subset:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 [57, 10, 53, 438, 369, 817011, 3000000, 3000000, 3000000, 30909, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 11, 9895, 1958, 8019, 17, 1219623, 3000000]\n",
      "27 [3000000, 863288, 602, 30124, 33742, 3000000, 3562, 3000000, 38263, 3000000, 3000000, 13860, 24, 20696, 3, 21322, 35, 3000000, 403, 1201, 8, 38263, 669, 1, 11, 36, 3000000]\n",
      "22 [228, 19, 29224, 438, 13, 3000000, 1635, 49, 101, 984, 141, 3000000, 11, 9, 473, 65530, 140, 11, 729, 24, 42, 3000000]\n",
      "37 [361, 52, 11, 1830, 12, 11, 943, 3000000, 915, 24, 3000000, 16, 343, 99, 11, 1557, 3000000, 11, 555, 1126, 68081, 4, 2633, 5481, 555, 3000000, 28, 920, 645, 1734, 3000000, 11, 20599, 3000000, 11, 1638, 3000000]\n",
      "8 [3000000, 2165064, 4, 11, 2520, 1722, 3000000, 3000000]\n"
     ]
    }
   ],
   "source": [
    "subset = [[embedding.key_to_index.get(word, len(embedding.key_to_index)-1) for word in sentence] for sentence in subset]\n",
    "for sentence in subset:\n",
    "    print(len(sentence), sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 [57, 10, 53, 438, 369, 817011, 3000000, 3000000, 3000000, 30909, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 11, 9895, 1958, 8019, 17, 1219623, 3000000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "37 [3000000, 863288, 602, 30124, 33742, 3000000, 3562, 3000000, 38263, 3000000, 3000000, 13860, 24, 20696, 3, 21322, 35, 3000000, 403, 1201, 8, 38263, 669, 1, 11, 36, 3000000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "37 [228, 19, 29224, 438, 13, 3000000, 1635, 49, 101, 984, 141, 3000000, 11, 9, 473, 65530, 140, 11, 729, 24, 42, 3000000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "37 [361, 52, 11, 1830, 12, 11, 943, 3000000, 915, 24, 3000000, 16, 343, 99, 11, 1557, 3000000, 11, 555, 1126, 68081, 4, 2633, 5481, 555, 3000000, 28, 920, 645, 1734, 3000000, 11, 20599, 3000000, 11, 1638, 3000000]\n",
      "37 [3000000, 2165064, 4, 11, 2520, 1722, 3000000, 3000000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "padded = torch.nn.utils.rnn.pad_sequence([torch.tensor(sentence) for sentence in subset], batch_first=True)\n",
    "for row in padded:\n",
    "    x = (list(i.item() for i in row))\n",
    "    print(len(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 37, 300])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDING_LAYER(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 70]) torch.Size([128, 70])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=True)\n",
    "\n",
    "for data, labels in train_loader:\n",
    "    print(data.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.4421174942501008\n",
      "Epoch 2 Loss: 0.2991996251401447\n",
      "Epoch 3 Loss: 0.2604514216146772\n",
      "Epoch 4 Loss: 0.24270207730550614\n",
      "Epoch 5 Loss: 0.2020429720481237\n",
      "Epoch 6 Loss: 0.19433646235201094\n",
      "Epoch 7 Loss: 0.18486985398663414\n",
      "Epoch 8 Loss: 0.18023936805270968\n",
      "Epoch 9 Loss: 0.17515609590780168\n",
      "Epoch 10 Loss: 0.16338102673254315\n"
     ]
    }
   ],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    embedding_matrix: torch.Tensor\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, embedding_matrix):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        hidden = torch.zeros(self.num_layers, x.shape[0], self.hidden_size)\n",
    "        output, _ = self.rnn(x, hidden)\n",
    "        output = self.fc(output)\n",
    "        return self.softmax(output)\n",
    "\n",
    "\n",
    "model = RNN(300, 128, 2, 27, embedding_matrix)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        output = model(data)\n",
    "        output = output.permute(0, 2, 1)\n",
    "        # only consider the words which were not padded\n",
    "        mask = (data != 0)\n",
    "        labels = labels * mask\n",
    "        mask = mask.unsqueeze(1).repeat(1, 27, 1)\n",
    "        output = output * mask.float()\n",
    "        loss = criterion(output, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    total_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 of 8\n",
      "Test Loss: 0.1823\n"
     ]
    }
   ],
   "source": [
    "# Calculate true positives and negatives, and false positives and negatives\n",
    "\n",
    "model.eval()\n",
    "\n",
    "true = []\n",
    "predicted = []\n",
    "\n",
    "loader = test_loader\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for p, (data, labels) in enumerate(loader):\n",
    "        output = model(data).permute(0, 2, 1)\n",
    "        mask = (data != 0)\n",
    "        labels = labels * mask\n",
    "        output = output * mask.unsqueeze(1).repeat(1, 27, 1).float()\n",
    "        total_loss += (loss := criterion(output, labels)).item()\n",
    "        true.extend(labels.flatten().tolist())\n",
    "        predicted.extend(output.argmax(dim=1).flatten().tolist())\n",
    "\n",
    "        print(p, \"of\", len(loader), end=\"\\r\")\n",
    "    total_loss /= len(loader)\n",
    "\n",
    "print()\n",
    "print(f\"Test Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyajeet Singh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512\n",
      "Precision: 0.4423\n",
      "Recall: 0.3812\n",
      "F1-Score: 0.3952\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "cf_matrix = confusion_matrix(true, predicted)\n",
    "acc = accuracy_score(true, predicted)\n",
    "prec = precision_score(true, predicted, average=\"macro\")\n",
    "rec = recall_score(true, predicted, average=\"macro\")\n",
    "f1 = f1_score(true, predicted, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(cf_matrix)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
